import numpy as np

import h5py

# generated by rockstar, contains the groups
FIN_ASCII = '/tigress/lthiele/Illustris_300-1_TNG/rockstar/out_99_wparents.list'

# generated by Arepo, contains the headers that we would like to preserve
FIN_HDF5  = '/tigress/lthiele/Illustris_300-1_TNG/output/groups_099/fof_subhalo_tab_099.0.hdf5'

FOUT_HDF5  = '/tigress/lthiele/Illustris_300-1_TNG/rockstar/out_99.hdf5'

# which fields to read -- defaults are factor=1, dtype=float32, filter=None, save=True, alias=None
# filter works in terms of the rescaled fields, i.e. factor is applied
READ_FIELDS = dict(M200c={'factor': 1e-10},
                   R200c={},
                   X    ={'factor': 1e3},
                   Y    ={'factor': 1e3},
                   Z    ={'factor': 1e3},
                   JX   ={'factor': 1e-7},
                   JY   ={'factor': 1e-7},
                   JZ   ={'factor': 1e-7},
                   Vmax ={},
                   Vrms ={},
                   Rs   ={},
                   VX   ={},
                   VY   ={},
                   VZ   ={},
                   Spin ={},
                   rs_klypin={},
                   M200c_all={'factor': 1e-10},
                   M200b={'factor': 1e-10},
                   M500c={'factor': 1e-10},
                   M2500c={'factor': 1e-10},
                   spin_bullock={},
                   b_to_a={},
                   c_to_a={},
                   Xoff ={}, # already in kpc/h
                   Voff ={}, # in km/s
                   PID  ={'dtype': int, 'filter': lambda x: x==-1, 'save': False})

# some fields should be stacked into multi-dimensional arrays
STACKS = dict(pos=['X', 'Y', 'Z'],
              vel=['VX', 'VY', 'VZ'],
              ang_mom=['JX', 'JY', 'JZ'])

# for these groups we simply copy all the attributes from FIN_HDF5 to FOUT_HDF5
# (no datasets, simply the simulation metaparameters)
# -- some attributes will be altered later
TO_COPY = ['Config', 'Header', 'Parameters']

                   
# figure out the indices of these columns
with open(FIN_ASCII, 'r') as f :
    header = f.readline()

# remove leading '#' and trailing '\n', and split into list
header = header.strip()[1:].split()

# find the column indices
for k, v in READ_FIELDS.items() :
    v['index'] = header.index(k)

# assemble input for loadtxt
names = list(READ_FIELDS.keys())
formats = list(v['dtype'] if 'dtype' in v else np.float32 for v in READ_FIELDS.values())
usecols = list(v['index'] for v in READ_FIELDS.values())

# load the data
A = np.loadtxt(FIN_ASCII, dtype={'names': names, 'formats': formats}, usecols=usecols)

# apply the rescalings
for k, v in READ_FIELDS.items() :
    if 'factor' in v :
        A[k] *= v['factor']

# filter the data
for k, v in READ_FIELDS.items() :
    if 'filter' in v :
        A = A[ v['filter'](A[k]) ]

# turn into a dict
A = { k: A[k] for k in READ_FIELDS.keys() }

# delete fields if not required
for k, v in READ_FIELDS.items() :
    if 'save' in v and not v['save'] :
        del A[k]

# stack fields together if required
for k, v in STACKS.items() :
    A[k] = np.stack(list(A[k1] for k1 in v), axis=-1)
    for k1 in v :
        del A[k1]

# get the number of groups
Ngroups = None
for v in A.values() :
    if Ngroups is None :
        Ngroups = len(v)
    else :
        assert len(v) == Ngroups

# now save to hdf5
with h5py.File(FOUT_HDF5, 'w') as fout, h5py.File(FIN_HDF5, 'r') as fin :

    # first copy the attributes
    for k in TO_COPY :
        gin  = fin[k]
        gout = fout.create_group(k)
        for k1, v1 in gin.attrs.items() :
            gout.attrs.create(k1, v1)

    # now alter some attributes that are not simulation metadata
    # use the modify method so as to preserve the original data types
    fout['Header'].attrs.modify('Ngroups_ThisFile', Ngroups)
    fout['Header'].attrs.modify('Ngroups_Total', Ngroups)

    # these are meaningless at this moment, set to impossible to prevent improper use
    fout['Header'].attrs.modify('Nids_ThisFile', -1)
    fout['Header'].attrs.modify('Nids_Total', -1)
    fout['Header'].attrs.modify('Nsubgroups_ThisFile', -1)
    fout['Header'].attrs.modify('Nsubgroups_Total', -1)

    # now add the data
    ggroup = fout.create_group('Group')

    for k, v in A.items() :
        ggroup.create_dataset(k, data=v)
